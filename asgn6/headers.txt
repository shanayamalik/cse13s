
Here is bag.h:
     1	#ifndef BAG_H            // Include guard to prevent multiple inclusions
     2	#define BAG_H
     3	
     4	#include <stdio.h>                 // Include the standard I/O library
     5	#include <stdlib.h>                // Include for memory allocation functions
     6	#include <stdbool.h>               // Include for boolean data type
     7	#include <string.h>                // Include for string manipulation functions
     8	
     9	#include "crawler.h"               // Include crawler header for webpage_t type
    10	
    11	// Structure for a node in the bag linked list
    12	typedef struct bag_node {
    13	    webpage_t *page;               // Pointer to a webpage_t, stored in the bag
    14	    struct bag_node *next;         // Pointer to the next node in the bag
    15	} bag_node_t;
    16	
    17	// Structure representing a bag (a simple stack)
    18	typedef struct {
    19	    bag_node_t *head;              // Pointer to the top node in the bag
    20	} bag_t;
    21	
    22	#endif //BAG_H

Here is crawler.h:
     1	#ifndef CRAWLER_H          // Include guard to prevent multiple inclusions
     2	#define CRAWLER_H
     3	
     4	#include <stddef.h>        // Include for general purpose standard library definitions
     5	#include <stdbool.h>       // Include for boolean data type
     6	#include <stdlib.h>        // Include for standard library functions
     7	
     8	// Structure definition for a webpage
     9	typedef struct {
    10	    char *url;            // Pointer to a string containing the URL of the webpage
    11	    char *html;           // Pointer to a string containing the HTML content of the webpage
    12	    size_t length;        // Length of the HTML content
    13	    int depth;            // Depth of the webpage in the crawling process
    14	} webpage_t;
    15	
    16	// Function prototype for malloc_with_check
    17	void *mem_malloc(size_t size);   // Custom malloc function with error checking
    18	// Function prototype for realloc_with_check
    19	void *mem_realloc(void *ptr, size_t size); // Custom realloc function with error checking
    20	// Function prototype for calloc_with_check
    21	void *mem_calloc(size_t nmemb, size_t size); // Custom calloc function with error checking
    22	// Function prototype for strdup_with_check
    23	char *mem_strdup(const char *s); // Custom strdup function with error checking
    24	// Function prototype for strndup_with_check
    25	char *mem_strndup(const char *s, size_t n); // Custom strndup function with error checking
    26	
    27	#endif // CRAWLER_H

Here is curl.h:
     1	#ifndef CURL_WRAPPER_H
     2	#define CURL_WRAPPER_H
     3	
     4	#include <stddef.h>
     5	
     6	/**
     7	 * This function attempts to download a webpage from a given URL. If it succeeds, it returns a
     8	 * pointer to a new string containing the contents of the webpage and sets the value at size_out to
     9	 * the length of the webpage contents. Otherwise, it returns null.
    10	 *
    11	 * Be sure to free the return value of this function when you're done with it.
    12	 */
    13	char * download(const char *url, size_t *size_out);
    14	
    15	#endif

Here is hashtable.h:
     1	#ifndef HASHTABLE_H            // Include guard to prevent multiple inclusions
     2	#define HASHTABLE_H
     3	
     4	#include <stdio.h>                 // Include the standard I/O library
     5	#include <stdlib.h>                // Include for memory allocation functions
     6	#include <stdbool.h>               // Include for boolean data type
     7	#include <string.h>                // Include for string manipulation functions
     8	
     9	#include "crawler.h"               // Include crawler header for webpage_t type
    10	
    11	// Structure for a node in the hashtable
    12	typedef struct hashtable_node {
    13	    char *key;                     // Pointer to the key string in the hashtable
    14	    struct hashtable_node *next;   // Pointer to the next node in the hashtable
    15	} hashtable_node_t;
    16	
    17	// Structure representing a hashtable
    18	typedef struct {
    19	    hashtable_node_t **table;      // Pointer to an array of pointers to hashtable nodes
    20	    size_t size;                   // Size of the hashtable (number of slots)
    21	} hashtable_t;
    22	
    23	// Function prototype to create a new hashtable
    24	hashtable_t *hashtable_create(size_t size);
    25	// Function prototype to insert a key into a hashtable
    26	bool hashtable_insert(hashtable_t *ht, const char *key);
    27	// Function prototype to check if a key is in a hashtable
    28	bool hashtable_lookup(const hashtable_t *ht, const char *key);
    29	// Function prototype to destroy a hashtable and free its resources
    30	void hashtable_destroy(hashtable_t *ht);
    31	
    32	#endif // HASHTABLE_H

Here is pagedir.h:
     1	#ifndef PAGEDIR_H
     2	#define PAGEDIR_H
     3	
     4	#include <stdbool.h>
     5	
     6	#include "crawler.h"
     7	
     8	/**
     9	 * Initializes the page directory so that webpages can be saved in it.
    10	 * Returns true if initialization succeeded, false otherwise.
    11	 */
    12	bool pagedir_init(const char *pageDirectory);
    13	
    14	/**
    15	 * Saves a given webpage to a given page directory with a given document ID.
    16	 */
    17	void pagedir_save(const webpage_t *page, const char *pageDirectory, const int documentID);
    18	
    19	#endif

Here is url.h:
     1	#ifndef URL_H
     2	#define URL_H
     3	
     4	#include <stdbool.h>
     5	
     6	/**
     7	 * Normalizes a URL. The return value is a pointer to memory allocated on the heap, so be sure to
     8	 * free what this function returns when you're done with it.
     9	 *
    10	 * The `base` argument must be a normalized URL.
    11	 * The `url` argument is the URL to be normalized.
    12	 *
    13	 * If `base` is "http://example.com/bar/baz" and `url` is "a/b/c", this function will return
    14	 * "http://example.com/bar/a/b/c".
    15	 */
    16	char * normalizeURL(const char *base, const char *url);
    17	
    18	/**
    19	 * Returns true if the webpage URL in the second argument is internal to the website from the first
    20	 * URL. Both URLs must be provided in normalized form.
    21	 */
    22	bool isInternalURL(const char *base, const char *to_validate);
    23	
    24	#endif
